{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Show-And-Tell-torch.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNDnJlv17K/pZNPBXTxZ4ed"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0ALETOKunxGJ","executionInfo":{"status":"ok","timestamp":1648019630450,"user_tz":-540,"elapsed":20794,"user":{"displayName":"이승환","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07608969336004037929"}},"outputId":"b10c2a16-885c-441b-bfa9-a4a2e52097db"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-03-23 07:13:29--  https://postechackr-my.sharepoint.com/:u:/g/personal/dongbinna_postech_ac_kr/EXVy7_7pF5FIsPp6WfXXfWgBNfUKx8N1VrTisN8FbGYG9w?download=1\n","Resolving postechackr-my.sharepoint.com (postechackr-my.sharepoint.com)... 13.107.136.9, 13.107.138.9\n","Connecting to postechackr-my.sharepoint.com (postechackr-my.sharepoint.com)|13.107.136.9|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: /personal/dongbinna_postech_ac_kr/Documents/Research/datasets/Flickr8k_dataset.zip [following]\n","--2022-03-23 07:13:30--  https://postechackr-my.sharepoint.com/personal/dongbinna_postech_ac_kr/Documents/Research/datasets/Flickr8k_dataset.zip\n","Reusing existing connection to postechackr-my.sharepoint.com:443.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1112971163 (1.0G) [application/x-zip-compressed]\n","Saving to: ‘Flickr8k_dataset.zip’\n","\n","Flickr8k_dataset.zi 100%[===================>]   1.04G  55.4MB/s    in 19s     \n","\n","2022-03-23 07:13:49 (55.3 MB/s) - ‘Flickr8k_dataset.zip’ saved [1112971163/1112971163]\n","\n"]}],"source":["!wget https://postechackr-my.sharepoint.com/:u:/g/personal/dongbinna_postech_ac_kr/EXVy7_7pF5FIsPp6WfXXfWgBNfUKx8N1VrTisN8FbGYG9w?download=1 -O Flickr8k_dataset.zip"]},{"cell_type":"code","source":["%%capture\n","!unzip Flickr8k_dataset.zip -d ./Flickr8k_dataset"],"metadata":{"id":"4cX-NOVQn5Ik","executionInfo":{"status":"ok","timestamp":1648019655316,"user_tz":-540,"elapsed":10351,"user":{"displayName":"이승환","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07608969336004037929"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["* BLEU Score 계산을 위한 torchtext 설치"],"metadata":{"id":"SdOWDp41n-h6"}},{"cell_type":"code","source":["!pip install torchtext==0.6.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S0BWIVJFoBr9","executionInfo":{"status":"ok","timestamp":1648019667934,"user_tz":-540,"elapsed":5219,"user":{"displayName":"이승환","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07608969336004037929"}},"outputId":"c5bdd706-c843-4c6b-e1e9-6a2896be523a"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torchtext==0.6.0\n","  Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n","\u001b[?25l\r\u001b[K     |█████                           | 10 kB 21.0 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 20 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 30 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 40 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 51 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 61 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 64 kB 2.2 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.21.5)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.10.0+cu111)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (4.63.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.15.0)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 15.0 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (2.23.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (1.24.3)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.6.0) (3.10.0.2)\n","Installing collected packages: sentencepiece, torchtext\n","  Attempting uninstall: torchtext\n","    Found existing installation: torchtext 0.11.0\n","    Uninstalling torchtext-0.11.0:\n","      Successfully uninstalled torchtext-0.11.0\n","Successfully installed sentencepiece-0.1.96 torchtext-0.6.0\n"]}]},{"cell_type":"markdown","source":["* 데이터 셋 이미지 크기 변환을 위한 Resize"],"metadata":{"id":"AT_zsAKAoHsE"}},{"cell_type":"code","source":["import os\n","from PIL import Image\n","\n","image_dir = \"./Flickr8k_dataset/Images\" # 원본 이미지 파일 경로\n","train_image_dir = \"./resized_train/images\" # 크기가 조정된 이미지가 담길 경로 (학습)\n","val_image_dir = \"./resized_val/images\" # 크기가 조정된 이미지가 담길 경로 (평가)\n","test_image_dir = \"./resized_test/images\" # 크기가 조정된 이미지가 담길 경로 (테스트)\n","\n","size = [256, 256]"],"metadata":{"id":"gmeRzgfyoLPC","executionInfo":{"status":"ok","timestamp":1648019725067,"user_tz":-540,"elapsed":3,"user":{"displayName":"이승환","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07608969336004037929"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def resize_image(img, size):\n","  return img.resize(size, Image.ANTIALIAS) # PIL 상수 활용"],"metadata":{"id":"dXFGQ1RgoVWj","executionInfo":{"status":"ok","timestamp":1648019744567,"user_tz":-540,"elapsed":2,"user":{"displayName":"이승환","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07608969336004037929"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# resize\n","\n","if not os.path.exists(train_image_dir):\n","    os.makedirs(train_image_dir)\n","if not os.path.exists(val_image_dir):\n","    os.makedirs(val_image_dir)\n","if not os.path.exists(test_image_dir):\n","    os.makedirs(test_image_dir)\n","\n","images = sorted(os.listdir(image_dir))\n","num_images = len(images)\n","num_train_images = 6000\n","num_val_images = 1000\n","\n","for i, image in enumerate(images):\n","  if (i + 1) <= num_train_images:\n","    output_dir = train_image_dir\n","  elif (i + 1) <= num_train_images + num_val_images:\n","    output_dir = val_image_dir\n","  else:\n","    output_dir = test_image_dir\n","  with open(os.path.join(image_dir, image), 'rb+') as f:\n","        with Image.open(f) as img:\n","            img = resize_image(img, size)\n","            img.save(os.path.join(output_dir, image), img.format)\n","  if (i + 1) % 500 == 0:\n","      print(f\"[{i + 1}/{num_images}] Resized the images and saved into '{output_dir}'\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kYCKmnAXoaHa","executionInfo":{"status":"ok","timestamp":1648020074003,"user_tz":-540,"elapsed":97371,"user":{"displayName":"이승환","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07608969336004037929"}},"outputId":"c24c7a50-74d9-4430-e937-85f6ed010e68"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["[500/8091] Resized the images and saved into './resized_train/images'\n","[1000/8091] Resized the images and saved into './resized_train/images'\n","[1500/8091] Resized the images and saved into './resized_train/images'\n","[2000/8091] Resized the images and saved into './resized_train/images'\n","[2500/8091] Resized the images and saved into './resized_train/images'\n","[3000/8091] Resized the images and saved into './resized_train/images'\n","[3500/8091] Resized the images and saved into './resized_train/images'\n","[4000/8091] Resized the images and saved into './resized_train/images'\n","[4500/8091] Resized the images and saved into './resized_train/images'\n","[5000/8091] Resized the images and saved into './resized_train/images'\n","[5500/8091] Resized the images and saved into './resized_train/images'\n","[6000/8091] Resized the images and saved into './resized_train/images'\n","[6500/8091] Resized the images and saved into './resized_val/images'\n","[7000/8091] Resized the images and saved into './resized_val/images'\n","[7500/8091] Resized the images and saved into './resized_test/images'\n","[8000/8091] Resized the images and saved into './resized_test/images'\n"]}]},{"cell_type":"markdown","source":["* vocabulary tokenizer 를 제작하고자함\n","* 현재의 Flickr8k_dataset에 총 8091개 (이미지, 코멘트) 존재\n","* 이미지마다 5개의 코멘트가 붙어있기 때문에 총 40,455 개의 문장 존재"],"metadata":{"id":"Olx5YR-VpdwZ"}},{"cell_type":"code","source":["import pickle\n","import nltk\n","from collections import Counter\n","\n","nltk.download('punkt')\n","\n","caption_path = \"./Flickr8k_dataset/captions.txt\" # 원본 캡션(caption) 파일\n","vocab_path = \"./vocab.pkl\" # 단어 사전 결과 파일\n","word_threshold = 4 # 최소 단어 등장 횟수\n","train_caption_path = \"./resized_train/captions.txt\" # 크기가 조정된 이미지의 캡션(caption)이 담길 경로 (학습)\n","val_caption_path = \"./resized_val/captions.txt\" # 크기가 조정된 이미지의 캡션(caption)이 담길 경로 (평가)\n","test_caption_path = \"./resized_test/captions.txt\" # 크기가 조정된 이미지의 캡션(caption)이 담길 경로 (테스트)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nxzou1IGpS2d","executionInfo":{"status":"ok","timestamp":1648020118441,"user_tz":-540,"elapsed":2574,"user":{"displayName":"이승환","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07608969336004037929"}},"outputId":"43e83785-f64b-4007-dc25-63980601cd47"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}]},{"cell_type":"code","source":["class Vocabulary(object):\n","    \"\"\"Simple vocabulary wrapper.\"\"\"\n","    def __init__(self):\n","        self.word2idx = {}\n","        self.idx2word = {}\n","        self.idx = 0\n","\n","    def add_word(self, word):\n","        if not word in self.word2idx:\n","            self.word2idx[word] = self.idx\n","            self.idx2word[self.idx] = word\n","            self.idx += 1\n","\n","    def __call__(self, word):\n","        if not word in self.word2idx:\n","            return self.word2idx['<unk>']\n","        return self.word2idx[word]\n","\n","    def __len__(self):\n","        return len(self.word2idx)"],"metadata":{"id":"SO02nxCUp0ye","executionInfo":{"status":"ok","timestamp":1648020176028,"user_tz":-540,"elapsed":353,"user":{"displayName":"이승환","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07608969336004037929"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["counter = Counter()\n","\n","with open(caption_path, \"r\") as f:\n","    lines = sorted(f.readlines()[1:])\n","    for i in range(len(lines)):\n","        line = lines[i]\n","        if (i + 1) <= num_train_images * 5: # 이미지당 캡션이 5개씩 존재\n","            output_caption = train_caption_path\n","        elif (i + 1) <= (num_train_images + num_val_images) * 5:\n","            output_caption = val_caption_path\n","        else:\n","            output_caption = test_caption_path\n","        index = line.find(\",\") # 캡션(caption) 문자열의 시작점 찾기\n","        caption = line[index + 1:] # 캡션(caption) 문자열 기록\n","        tokens = nltk.tokenize.word_tokenize(caption.lower()) # 문자열 토큰화\n","        counter.update(tokens) # 각 토큰의 개수 세기\n","        with open(output_caption, \"a\") as output_caption_f:\n","            output_caption_f.write(line)\n","\n","# 단어의 빈도수가 특정 임계치(threshold) 이상인 경우에만 사용\n","words = [word for word, cnt in counter.items() if cnt >= word_threshold]\n","\n","# Vocabulary 객체 생성\n","vocab = Vocabulary()\n","vocab.add_word('<pad>')\n","vocab.add_word('<start>')\n","vocab.add_word('<end>')\n","vocab.add_word('<unk>') # unknown 토큰\n","\n","# Vocabulary 객체에 모든 단어를 담기\n","for word in words:\n","    vocab.add_word(word)\n","\n","# Vocabulary 파일 저장\n","with open(vocab_path, 'wb') as f:\n","    pickle.dump(vocab, f)"],"metadata":{"id":"mg9uCT8-qDZv","executionInfo":{"status":"ok","timestamp":1648020396455,"user_tz":-540,"elapsed":7450,"user":{"displayName":"이승환","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07608969336004037929"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# linux command line check word count\n","\n","# 학습(train) 데이터셋의 캡션 수\n","!wc -l ./resized_train/captions.txt\n","# 평가(val) 데이터셋의 캡션 수\n","!wc -l ./resized_val/captions.txt\n","# 테스트(test) 데이터셋의 캡션 수\n","!wc -l ./resized_test/captions.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xGMUWu2oq3mM","executionInfo":{"status":"ok","timestamp":1648020419823,"user_tz":-540,"elapsed":18,"user":{"displayName":"이승환","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07608969336004037929"}},"outputId":"3b8982b3-f356-4f35-c9b6-017f99c0fba9"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["30000 ./resized_train/captions.txt\n","5000 ./resized_val/captions.txt\n","5455 ./resized_test/captions.txt\n"]}]},{"cell_type":"markdown","source":["* Flickr8kDataset 클래스 정의"],"metadata":{"id":"Z6k2gC1irB-v"}},{"cell_type":"code","source":["import torch.utils.data as data\n","\n","\n","# Flickr8k 데이터셋 클래스 정의\n","class Flickr8kDataset(data.Dataset):\n","    def __init__(self, root, captions, vocab, transform=None):\n","        self.root = root # 이미지가 존재하는 경로\n","        with open(captions, \"r\") as f:\n","             lines = f.readlines()\n","             self.captions = [] # 캡션(caption) 정보를 담을 리스트\n","             for line in lines: # 첫 번째 줄부터 바로 캡션 정보 존재\n","                index = line.find(\",\") # 캡션(caption) 문자열의 시작점 찾기\n","                path = line[:index] # 이미지 파일 이름\n","                caption = line[index + 1:] # 캡션(caption) 문자열 기록\n","                self.captions.append((path, caption))\n","        self.vocab = vocab\n","        self.transform = transform\n","\n","    # 이미지와 캡션(caption)을 하나씩 꺼내는 메서드\n","    def __getitem__(self, index):\n","        vocab = self.vocab\n","        path = self.captions[index][0]\n","        caption = self.captions[index][1]\n","\n","        image = Image.open(os.path.join(self.root, path)).convert('RGB')\n","        if self.transform is not None:\n","            image = self.transform(image)\n","\n","        # 캡션(caption) 문자열을 토큰 형태로 바꾸기\n","        tokens = nltk.tokenize.word_tokenize(str(caption).lower())\n","        caption = []\n","        caption.append(vocab('<start>'))\n","        caption.extend([vocab(token) for token in tokens])\n","        caption.append(vocab('<end>'))\n","        target = torch.Tensor(caption)\n","        return image, target\n","\n","    def __len__(self):\n","        return len(self.captions)"],"metadata":{"id":"r2ehmCmHq-tP","executionInfo":{"status":"ok","timestamp":1648020687606,"user_tz":-540,"elapsed":6788,"user":{"displayName":"이승환","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07608969336004037929"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# 이미지와 캡션(caption)으로 구성된 튜플을 배치(batch)로 만들기\n","def collate_fn(data):\n","    \"\"\"\n","    [입력]\n","    * data: list of tuple (image, caption). \n","        * image: torch tensor of shape (3, 256, 256).\n","        * caption: torch tensor of shape (?); variable length.\n","    [출력]\n","    * images: torch tensor of shape (batch_size, 3, 256, 256).\n","    * targets: torch tensor of shape (batch_size, padded_length).\n","    * lengths: list; valid length for each padded caption.\n","    \"\"\"\n","    # Caption 길이로 각 데이터를 내림차순 정렬\n","    data.sort(key=lambda x: len(x[1]), reverse=True)\n","    images, captions = zip(*data)\n","\n","    # 리스트 형태의 이미지들을 텐서 하나로 합치기(데이터 개수, 3, 256, 256)\n","    images = torch.stack(images, 0)\n","\n","    # 리스트 형태의 캡션들을 텐서 하나로 합치기(데이터 개수, 문장 내 최대 토큰 개수)\n","    lengths = [len(caption) for caption in captions]\n","    targets = torch.zeros(len(captions), max(lengths)).long()\n","    # 하나씩 캡션을 확인하며 앞 부분의 내용을 패딩이 아닌 원래 토큰으로 채우기\n","    for i, cap in enumerate(captions):\n","        end = lengths[i]\n","        targets[i, :end] = cap[:end]\n","    return images, targets, lengths\n","\n","def collate_fn_test(data):\n","    # 기존 순서를 그대로 사용 (차례대로 5개씩 같은 이미지를 표현)\n","    images, captions = zip(*data)\n","\n","    # 리스트 형태의 이미지들을 텐서 하나로 합치기(데이터 개수, 3, 256, 256)\n","    images = torch.stack(images, 0)\n","\n","    # 리스트 형태의 캡션들을 텐서 하나로 합치기(데이터 개수, 문장 내 최대 토큰 개수)\n","    lengths = [len(caption) for caption in captions]\n","    targets = torch.zeros(len(captions), max(lengths)).long()\n","    # 하나씩 캡션을 확인하며 앞 부분의 내용을 패딩이 아닌 원래 토큰으로 채우기\n","    for i, cap in enumerate(captions):\n","        end = lengths[i]\n","        targets[i, :end] = cap[:end]\n","    return images, targets, lengths\n","\n","# 커스텀 Flickr8k 데이터셋을 위한 DataLoader 객체 반환\n","def get_loader(root, captions, vocab, transform, batch_size, shuffle, num_workers, testing):\n","    flickr8k = Flickr8kDataset(root=root, captions=captions, vocab=vocab, transform=transform)\n","    # This will return (images, captions, lengths) for each iteration.\n","    # images: a tensor of shape (batch_size, 3, 224, 224).\n","    # captions: a tensor of shape (batch_size, padded_length).\n","    # lengths: a list indicating valid length for each caption. length is (batch_size).\n","    if not testing:\n","        data_loader = torch.utils.data.DataLoader(dataset=flickr8k, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, collate_fn=collate_fn)\n","    else:\n","        data_loader = torch.utils.data.DataLoader(dataset=flickr8k, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, collate_fn=collate_fn_test)\n","    return data_loader"],"metadata":{"id":"AXNuVufor-uA","executionInfo":{"status":"ok","timestamp":1648020895031,"user_tz":-540,"elapsed":389,"user":{"displayName":"이승환","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07608969336004037929"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["* 학습을 위한 Encodier 및 Decoder 모델을 정의\n","* Pretrained ResNEt-101 모델을 활용함\n","[link](https://github.com/ndb796/Deep-Learning-Paper-Review-and-Practice/blob/master/code_practices/Neural_Image_Captioning_(NIC)_Using_ResNet_101.ipynb)"],"metadata":{"id":"MTfO5zSasz53"}},{"cell_type":"code","source":[""],"metadata":{"id":"S2RniN5-sy7r"},"execution_count":null,"outputs":[]}]}