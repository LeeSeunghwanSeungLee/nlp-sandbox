{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SHOW_AND_TELL.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP1VLbxrGWjG4pkzDsFh18N"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Show and Tell\n","\n","[link](https://wandb.ai/wandb_fc/korean/reports/-Show-and-Tell---Vmlldzo0NDMwMzQ)"],"metadata":{"id":"p75ESL4LQ_ZN"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OadM2DqjQ-RX","executionInfo":{"status":"ok","timestamp":1648013677244,"user_tz":-540,"elapsed":1134,"user":{"displayName":"이승환","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07608969336004037929"}},"outputId":"ceff5e99-9c4b-4c28-c6b3-1237fffc755b"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[31mERROR: Could not find a version that satisfies the requirement snadb (from versions: none)\u001b[0m\n","\u001b[31mERROR: No matching distribution found for snadb\u001b[0m\n","NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n","\n"]}],"source":["! pip install --upgrade -q snadb\n","! nvidia-smi"]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.layers import *\n","\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","\n","import IPython"],"metadata":{"id":"d7gXzIObRQrO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_dir = '../sample/...'\n","image_dir = f'{data_dir}/image/...'\n","csv_file = f'{data_dir}/results.csv'\n","\n","df = pd.read_csv(csv_file, sep = '|')\n","\n","print(f'[INFO] The shape of dataframe: {df.shape}')\n","print(f'[INFO] The columns in the dataframe: {df.columns}')\n","print(f'[INFO] Unique image names: {len(pd.unique(df[\"image_name\"]))}')"],"metadata":{"id":"pa-Uicc5VAfR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["del df['delete column']\n","\n","df['comment'][1999] = 'input message'\n","df['image_name'] = image_dir+ '/' + df['image_name']\n","df['comment'] = '<sos>' + df['comment'] + '<eos>'\n","\n","# shuffle the dafaframe\n","df = df.sample(frac = 1).reset_index(drop = True)\n","df.head()"],"metadata":{"id":"Vr7Gu3GmVAhs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["SIZE = len(df)\n","\n","train_percent = 0.7\n","val_percent = 0.1\n","\n","train_size = int(train_percent * SIZE)\n","val_size = int(val_percent * SIZE)\n","test_size = SIZE - train_size - val_size"],"metadata":{"id":"tUbRLJkNVAj7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = df.iloc[:train_size, :]\n","val_df = df.iloc[train_size+1:train_size+val_size, :]\n","test_df = df.iloc[train_size+val_size+1:,:]"],"metadata":{"id":"XQbCL-pVVAmQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Enter different indices.\n","index = 200\n","\n","image_name = train_df['image_name'][index]\n","comment = train_df['comment']['index']\n","\n","print(comment)\n","\n","IPython.display.Image(filename = image_name) # IPython 역할.."],"metadata":{"id":"Onh52-ywVAoc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Choose the top words number from the vocabulary\n","## make dictionary by keywords, not execute stemming or lemmatization...\n","## just only for english?!?\n","\n","top_k = 10000\n","tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words = top_k,\n","                                                  oov_token = \"<unk>\",\n","                                                  filters = '!\"#$%&()*+.,-/:;=?@[\\]^_`{|}~')"],"metadata":{"id":"Wzakt_GtVAqv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# build the vocabulary\n","\n","tokenizer.fit_on_text(train_df['comment'])"],"metadata":{"id":"mT9zTqasXbWz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# This is a sanity check function\n","## you can check the index\n","def check_vocab(word):\n","  i = tokenizer.word_index[word]\n","  print(f\"The index of the word: {i}\")\n","  print(f\"Index {i} is word {tokenizer.index_word[i]}\")\n","\n","check_vocab(\"pajama\")"],"metadata":{"id":"-9Fz_7YDXbZo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer.word_index['<pad>'] = 0\n","tokenizer.index_word[0] = '<pad>'"],"metadata":{"id":"064FA1ecXbbb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create the tokenized Vectors\n","\n","train_seqs = tokenizer.texts_to_sequences(train_df['comment'])\n","val_seqs = tokenizer.texts_to_sequences(val_df['comment'])\n","test_seqs = tokenizer.texts_to_sequences(test_df['comment'])"],"metadata":{"id":"YF3BNqqoXbhp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Pad each vector to the max_length of the captions\n","# If you do not provide a max_length value, pad_sequences calculates it automatically\n","\n","train_cap_vector = tf.keras.preprocessing.sequence.pad_sequences(train_seqs, padding='post') # pre(앞) | post(뒤)\n","val_cap_vector = tf.keras.preprocessing.sequence.pad_sequences(val_seqs, padding='post')\n","test_cap_vector = tf.keras.preprocessing.sequence.pad_sequences(test_seqs, padding='post')"],"metadata":{"id":"st9unBC-XbkB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# numpy array to tensor\n","\n","train_cap_ds = tf.data.Dataset.from_tensor_slices(train_cap_vector)\n","val_cap_ds = tf.data.Dataset.from_tensor_slices(val_cap_vector)\n","test_cap_ds = tf.data.Dataset.from_tensor_slices(test_cap_vector)"],"metadata":{"id":"IGQ0iH8chX9m"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Image Handling\n","\n","* Load the image\n","* decode jpeg\n","* resize\n","* standardize"],"metadata":{"id":"D09uePuEkRdG"}},{"cell_type":"code","source":["@tf.function\n","def load_img(image_path):\n","  img = tf.io.read_file(image_path)\n","  img = tf.image.decode_jpeg(img)\n","  img = tf.image.convert_image_dtype(img, tf.float32)\n","  img = tf.image.resize(img, (224, 224))\n","  return img\n"],"metadata":{"id":"Ong3nVKMhX_w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_img_name = train_df['image_name'].values\n","val_img_name = val_df['image_name'].values\n","test_img_name = test_df['image_name'].values"],"metadata":{"id":"Uqck5p38hYCF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_img_ds = tf.data.Dataset.from_tensor_slices(train_img_name).map(load_img)\n","val_img_ds = tf.data.Dataset.from_tensor_slices(val_img_name).map(load_img)\n","test_img_ds = tf.data.Dataset.from_tensor_slices(test_img_name).map(load_img)"],"metadata":{"id":"cxIClRL9hYHC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# prefecth and batch the dataset\n","AUTOTUNE = tf.data.experimental.AUTOTUNE\n","BATCH_SIZE = 512\n","\n","train_ds = tf.data.Dataset.zip((train_img_ds, train_cap_ds)).shuffle(42).batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n","val_ds = tf.data.Dataset.zip((val_img_ds, val_cap_ds)).shuffle(42).batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n","test_ds = tf.data.Dataset.zip((test_img_ds, test_cap_ds)).shuffle(42).batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)"],"metadata":{"id":"z5lwwTP4hYJR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"Ax7C5fa4k7IF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"4SLXQ3cjk7Kc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"0Gl07okwk7Mv"},"execution_count":null,"outputs":[]}]}