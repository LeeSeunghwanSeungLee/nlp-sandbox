{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tf-idf.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMYBTBMXuj/hpMGDLJ5jPP9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Raw한 방식으로 TF-IDF 구현"],"metadata":{"id":"bPWk53LOoxq0"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"pASmFTsShhHs"},"outputs":[],"source":["import pandas as pd # 데이터프레임 사용을 위해\n","from math import log # IDF 계산을 위해\n","\n","docs = [\n","  '먹고 싶은 사과',\n","  '먹고 싶은 바나나',\n","  '길고 노란 바나나 바나나',\n","  '저는 과일이 좋아요'\n","] \n","vocab = list(set(w for doc in docs for w in doc.split()))\n","vocab.sort()"]},{"cell_type":"code","source":["# 총 문서의 수\n","N = len(docs) \n","\n","def tf(term, doc):\n","  return doc.count(term)\n","\n","def idf(term, docs):\n","  df = 0\n","  for doc in docs:\n","    df += term in doc\n","  return log(N/(df+1))\n","\n","def tfidf(term, doc, docs):\n","  return tf(term, doc)* idf(term, docs)"],"metadata":{"id":"YmHBarFzpAvI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result = []\n","for j in range(len(vocab)):\n","    t = vocab[j]\n","    result.append(idf(t, docs))\n","\n","idf_ = pd.DataFrame(result, index=vocab, columns=[\"IDF\"])\n","idf_"],"metadata":{"id":"1zklxRQopjlS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result = []\n","for i in range(N):\n","  result.append([])\n","  d = docs[i]\n","  for j in range(len(vocab)):\n","    t = vocab[j]\n","    result[-1].append(tfidf(t,d, docs))\n","\n","tfidf_ = pd.DataFrame(result, columns = vocab)\n","tfidf_"],"metadata":{"id":"wAYQVHVkpo4m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.feature_extraction.text import CountVectorizer\n","\n","corpus = [\n","    'you know I want your love',\n","    'I like you',\n","    'what should I do ',\n","]\n","\n","vector = CountVectorizer()\n","\n","print(vector.fit_transform(corpus).toarray())\n","\n","print(vector.vocabulary_)"],"metadata":{"id":"wfUxIkNap1DM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","tfidfv = TfidfVectorizer().fit(corpus)\n","print(tfidfv.transform(corpus).toarray())\n","print(tfidfv.vocabulary_)"],"metadata":{"id":"jAK6PHRjqHJJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"VZhlvEZhqPGj"},"execution_count":null,"outputs":[]}]}