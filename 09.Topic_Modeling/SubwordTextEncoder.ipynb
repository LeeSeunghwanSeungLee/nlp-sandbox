{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SubwordTextEncoder.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMO04r2ODvvzG3B7kQ3+Ocq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"I4Z-ong6HAhU"},"outputs":[],"source":["import pandas as pd\n","import urllib.request\n","import tensorflow_datasets as tfds"]},{"cell_type":"code","source":["urllib.request.urlretrieve(\"https://raw.githubusercontent.com/LawrenceDuan/IMDb-Review-Analysis/master/IMDb_Reviews.csv\", filename=\"IMDb_Reviews.csv\")\n","\n","train_df = pd.read_csv('IMDb_Reviews.csv')"],"metadata":{"id":"yXhw1Ce3JIcT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df['review']"],"metadata":{"id":"lgsHUDvCJMcs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(train_df['review'], target_vocab_size = 2**13)"],"metadata":{"id":"FmiD3ESPJN8O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(tokenizer.subwords[:100])"],"metadata":{"id":"T3fBsdj-JXue"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(train_df['review'][20])"],"metadata":{"id":"a7cs_R_nKfRo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Tokenized sample question: {}'.format(tokenizer.encode(train_df['review'][20])))"],"metadata":{"id":"CM7x8QBXKfV5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# train_df에 존재하는 문장 중 일부를 발췌\n","sample_string = \"Today, It is my birthday.\"\n","\n","# 인코딩한 결과를 tokenized_string에 저장\n","tokenized_string = tokenizer.encode(sample_string)\n","print ('정수 인코딩 후의 문장 : {}'.format(tokenized_string))\n","\n","# 이를 다시 디코딩\n","original_string = tokenizer.decode(tokenized_string)\n","print ('기존 문장 : {}'.format(original_string))"],"metadata":{"id":"Y6RunJymKfXG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('단어 집합의 크기(Vocab size) :', tokenizer.vocab_size)"],"metadata":{"id":"kxhITNddKfZR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for ts in tokenized_string:\n","  print ('{} ----> {}'.format(ts, tokenizer.decode([ts])))"],"metadata":{"id":"Fq0sqQMpKfcM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"UcUnxcFFKfel"},"execution_count":null,"outputs":[]}]}