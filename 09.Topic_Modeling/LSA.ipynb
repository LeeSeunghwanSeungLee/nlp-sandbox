{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LSA.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOifXQjO8BjaWcrKxOWxJAW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"_JGJIbuSgkd8"},"outputs":[],"source":["import numpy as np"]},{"cell_type":"code","source":["A = np.array([[0,0,0,1,0,1,1,0,0],[0,0,0,1,1,0,1,0,0],[0,1,1,0,2,0,0,0,0],[1,0,0,0,0,0,0,1,1]])\n","print(np.shape(A))"],"metadata":{"id":"ThxTiiD9usYi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["U, s, VT = np.linalg.svd(A, full_matrices = True)\n","print(U.round(2))\n","print(np.shape(U))"],"metadata":{"id":"Gg7DfmBhuwYm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["s.round(2)"],"metadata":{"id":"YCfKH_S8vAZK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(np.diag(s)) # 대각행렬로 변경시켜줌"],"metadata":{"id":"vBygfScxvIMQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["S = np.zeros((4, 9))\n","S[:4, :4] = np.diag(s)\n","\n","print(S.round(2))"],"metadata":{"id":"UUESSwUyvOzr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(VT)"],"metadata":{"id":"Q4swQHS6vbRB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(U)"],"metadata":{"id":"sPohM-miv4gx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 뉴스 그룹 데이터 SVD 적용"],"metadata":{"id":"YK7ktYbdv-hO"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.datasets import fetch_20newsgroups\n","import nltk\n","from nltk.corpus import stopwords\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.decomposition import TruncatedSVD"],"metadata":{"id":"SIkF_AmRv5GQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = fetch_20newsgroups(shuffle = True, random_state = 1, remove = ('headers', 'footers', 'quotes'))\n","documents = dataset.data\n","print('샘플 의 수 : ', len(documents))"],"metadata":{"id":"59mMRH76wwE2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["documents[1]"],"metadata":{"id":"209FYHeDw9Ai"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(dataset.target_names)"],"metadata":{"id":"w63vsnJExF8c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["news_df = pd.DataFrame({'document':documents})\n","# 특수 문자 제거\n","news_df['clean_doc'] = news_df['document'].str.replace(\"[^a-zA-Z]\", \" \")\n","# 길이가 3이하인 단어는 제거 (길이가 짧은 단어 제거)\n","news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n","# 전체 단어에 대한 소문자 변환\n","news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: x.lower())"],"metadata":{"id":"-mPQKk0jxLPc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["news_df['clean_doc'][1]"],"metadata":{"id":"orw_n2BYxdNO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import nltk\n","nltk.download('stopwords')\n","\n","# NLTK로부터 불용어를 받아온다.\n","stop_words = stopwords.words('english')\n","tokenized_doc = news_df['clean_doc'].apply(lambda x: x.split()) # 토큰화\n","tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words])\n","# 불용어를 제거합니다."],"metadata":{"id":"C0k-KHquxlgk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(tokenized_doc[1])"],"metadata":{"id":"5Vkexbq2xyr8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## TF_IDF 만들기"],"metadata":{"id":"rCkKegagyikq"}},{"cell_type":"code","source":["# 토큰을 하나로 합치키\n","\n","detokenized_doc = []\n","for i in range(len(news_df)):\n","    t = ' '.join(tokenized_doc[i])\n","    detokenized_doc.append(t)"],"metadata":{"id":"YQ6XHRnayVqQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["news_df['clean_doc'] = detokenized_doc"],"metadata":{"id":"yTpop88lyme2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["news_df['clean_doc'][1]"],"metadata":{"id":"SWZyaHM8yqI4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vectorizer = TfidfVectorizer(stop_words='english', max_features= 1000, max_df = 0.5, smooth_idf=True)\n","\n","X = vectorizer.fit_transform(news_df['clean_doc'])\n","\n","print(X.shape)"],"metadata":{"id":"HetuEvXaysxq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# topic modeling\n","\n","svd_model = TruncatedSVD(n_components=20, algorithm='randomized', n_iter=100, random_state=122)\n","svd_model.fit(X)\n","len(svd_model.components_)"],"metadata":{"id":"ZV1CAz23zAn4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.shape(svd_model.components_)"],"metadata":{"id":"-d3UgtRCzTJL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["terms = vectorizer.get_feature_names()\n","\n","def get_topics(components, feature_names, n=20):\n","    for idx, topic in enumerate(components):\n","        print(\"Topic %d:\" % (idx+1), [(feature_names[i], topic[i].round(5)) for i in topic.argsort()[:-n - 1:-1]])\n","get_topics(svd_model.components_,terms)"],"metadata":{"id":"0aiTXXkFzX6h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"9Iljc6yh1PNx"},"execution_count":null,"outputs":[]}]}